{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The **Lorenz system** is a system of ordinary differential equations first studied by mathematician and meteorologist Edward Lorenz. The notable thing about this system is that for a certain subset of parameters and initial conditions it yields chaotic solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It consist on 3 coupled differential equations.\n",
    "\n",
    "#### dx/dt = sigma * (y-x)\n",
    "\n",
    "#### dy/dt = x * (rho-z) - y\n",
    "\n",
    "#### dz/dt = xy - beta*z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The idea would be to first solve the Lorenz system numerically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Lorenz system\n",
    "def lorenz(w, t, sigma, rho, beta):\n",
    "    x, y, z = w\n",
    "    dwdt = [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "    return dwdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions: [x(t = 0), y(t = 0), z(t = 0)]\n",
    "w0 = [1.0, 0.0, 0.0]\n",
    "\n",
    "# Define a time vector:\n",
    "t = np.linspace(0, 30, 3001)\n",
    "\n",
    "# Define the system parameters\n",
    "sigma = 10\n",
    "rho = 28\n",
    "beta = 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the system\n",
    "sol = odeint(lorenz, w0, t, args=(sigma, rho, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Plots\n",
    "\n",
    "### Now that we have the solution for the spatial coordinates, we can see how they change with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y, z = sol[:, 0], sol[:, 1], sol[:, 2]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(t, x, label='x(t)')\n",
    "plt.title('Time Series of x')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('x')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(t, y, label='y(t)')\n",
    "plt.title('Time Series of y')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(t, z, label='z(t)')\n",
    "plt.title('Time Series of z')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('z')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the fact that the spatial coordinates exhibit oscillatory behavior, it is difficult to extract meaningful insights from this representation. Next, we can plot the trajectory and its projection onto different planes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x, y, label='y vs x')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Trajectory - Projection onto the yx plane')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(y, z, label='z vs y')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('z')\n",
    "plt.title('Trajectory - Projection onto the zy plane')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(x, z, label='z vs x')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('z')\n",
    "plt.title('Trajectory - Projection onto the zx plane')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectory in 3D\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(x, y, z, label='Trajectory in 3D Space')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "ax.set_title('3D Trajectory')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Matplotlib has two interfaces:\n",
    "\n",
    "*   **Axes interface** (object-based, explicit): create a *Figure* and one or more *Axes* objects, then explicitly use methods on these objects to add data, configure limits, set labels etc\n",
    "\n",
    "*   **pyplot interface** (function-based, implicit): consists of functions in the *pyplot* module. Figure and Axes are manipulated through these functions and are only implicitly present in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Animated Trajectory Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuncAnimation is a class in the matplotlib.animation module\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['animation.embed_limit'] = 100  # Set embed limit to 100 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and axes. I would like to visualize the animation on the zx plane\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(np.min(x), np.max(x))\n",
    "ax.set_ylim(np.min(z), np.max(z))\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('z')\n",
    "ax.set_title('Trajectory - Projection onto the zx plane')\n",
    "\n",
    "line, = ax.plot([], [], lw=2)\n",
    "\n",
    "# Initialize the animation\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return line,\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    line.set_data(x[:frame], z[:frame])\n",
    "    return line,\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update, frames=len(t), init_func=init, blit=True, interval=20)\n",
    "HTML(ani.to_jshtml())  # This will display the animation in the notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "ani.save('phase_space_animation.gif', writer='Pillow', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train some ML models for accomplish simple tasks with the Lorenz system, beggining with a common regression task, like predicting the position in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independently of the task at hand (and hence the type of model chosen), there are essential steps to be followed. These steps form a workflow that serves as a structured guide applicable to a wide range of machine learning implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Summary:\n",
    "\n",
    "1. **Data collection**: in this case, numerical data is needed to train the ML model. The  numerical solutions obtained in the previous step can be used to feed the model. This data however needs to be structured in a particular way, depending on the task and model used. \n",
    "\n",
    "2. **Feature extraction**: features are the inputs to the ML model. Is important to identify the most relevant features for making predictions (*feature importance*) for example, using techniques like SHAP values. On a later stage, more sophisticated features can be added using domain-specific knowledge (*feature engineering*). Basic features include in time forecasting are the raw time series and/or their derivatives. Lagged features can help to capture more complex time dependencies. Advance features include statistical ones like mean, variance or the Fourier transforms. \n",
    "\n",
    "3. **Model Selection and Training**: model selection depends on the task at hand.\n",
    "    * *split the data* : data is divided into training and testing sets\n",
    "\n",
    "    * *training process* : train the model on the training data. Techniques like **cross-validation** can be used to ensure that the model's performance is not due to overfitting or specific to the training data split.\n",
    "\n",
    "    * *hyperparameter tuning* : model parameter optimization can be done using grid search, random search, or Bayesian optimization.\n",
    "\n",
    "4. **Evaluate model performance**: performance of the ML model can be assessed by comparing their predictions with the actual behavior of the system. This can be done using quantitative metrics and visual tools.\n",
    "\n",
    "    * *Quantitative metrics* : for regression problems popular metrics are MSE, MAE and RMSE. For classification problems metrics include Accuracy, Precision, Recall, F1-Score, and ROC AUC.\n",
    "\n",
    "    * *Visualization tools* : Prediction vs. Actual - Plot the predicted time series against the actual time series to visually inspect the model’s performance - Residual Analysis and Confusion Matrix (for classification)\n",
    "\n",
    "5. **Model Refinement** : based on performance insights, model can be tuned by ways of Feature Engineering, combining multiple methods (Ensemble Methods) and Hyperparameter Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Future States (Regression Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple regression task, for that reason I'm using only the time series x(t), y(t) and z(t) as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any ML application, the data needs to be structured in a certain way (depending on the application). For a simple regression task (supervised learning), each sample is represented by features and a target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Building the dataframe: include the time variable and the time series for the spatial coordinates as features\n",
    "df = pd.DataFrame(sol, columns=['x', 'y', 'z'])\n",
    "\n",
    "# Include the time variable as well\n",
    "df['t'] = t\n",
    "df = df[['t','x', 'y', 'z']]\n",
    "\n",
    "# Create target columns for future states\n",
    "df['x_future'] = df['x'].shift(-1)\n",
    "df['y_future'] = df['y'].shift(-1)\n",
    "df['z_future'] = df['z'].shift(-1)\n",
    "\n",
    "# Drop the last row since it has NaN targets\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x_future</th>\n",
       "      <th>y_future</th>\n",
       "      <th>z_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917924</td>\n",
       "      <td>0.266340</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.917924</td>\n",
       "      <td>0.266340</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.867919</td>\n",
       "      <td>0.511740</td>\n",
       "      <td>0.004670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.867919</td>\n",
       "      <td>0.511740</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.845360</td>\n",
       "      <td>0.744654</td>\n",
       "      <td>0.009883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.845360</td>\n",
       "      <td>0.744654</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.846806</td>\n",
       "      <td>0.972331</td>\n",
       "      <td>0.016842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.846806</td>\n",
       "      <td>0.972331</td>\n",
       "      <td>0.016842</td>\n",
       "      <td>0.869786</td>\n",
       "      <td>1.201129</td>\n",
       "      <td>0.025688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      t         x         y         z  x_future  y_future  z_future\n",
       "0  0.00  1.000000  0.000000  0.000000  0.917924  0.266340  0.001266\n",
       "1  0.01  0.917924  0.266340  0.001266  0.867919  0.511740  0.004670\n",
       "2  0.02  0.867919  0.511740  0.004670  0.845360  0.744654  0.009883\n",
       "3  0.03  0.845360  0.744654  0.009883  0.846806  0.972331  0.016842\n",
       "4  0.04  0.846806  0.972331  0.016842  0.869786  1.201129  0.025688"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have structured the data and identified the features, I have to do the model selection and training part.\n",
    "\n",
    "Because I would like to perform a simple regression task (predict future values of the time series) I'll start with a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the variables properly\n",
    "\n",
    "# x, y and z are the features.\n",
    "X = df[['x','y','z']]\n",
    "\n",
    "# x_future\ty_future\tz_future are the target labels\n",
    "Y = df[['x_future','y_future','z_future']]\n",
    "\n",
    "# Split the data. In this case, the split will be 80-20\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)   # random state for reproducibility\n",
    "\n",
    "## Feature scaling: each feature in the dataset is standardized by removing the mean and scaling to unit variance. Feature scaling is an important step in data preprocessing, especially for algorithms that are sensitive to the scale of the data\n",
    "\n",
    "# create an instance of the 'StandardScaler' class\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data is important because some algorithms work better or converge faster when the features are on a similar scale.\n",
    "\n",
    "StandardScaler object calculates the mean and SD of each feature, and scales each data point (e.g if x is an observation of feature x, x_scaled = (x - mu)/sigma) so as the scaled distribution has mean = 0 and sd = 1\n",
    "\n",
    "the method fit_transform(X_train) fits the scaler by calculating the mean and sd of the X_train set, and subsequently scales the data distribution by applying the corresponding transformation\n",
    "\n",
    "the method transform(X_test) scales the X_test set using the already fitted scaler. Is important to clarify that the transformation is done by substracting and dividing by the mean and sd of the X_train distribution, not by calculating the mean and sd of X_train. By using the same scaling parameters for both data distributions, we ensure that the model sees data on the same scale during training and testing.\n",
    "\n",
    "Is important to remember always compute mean and standard deviation from the training data and apply the same transformation to any new data (e.g., validation or test sets). It is possible to reverse the standardization process using scaler.inverse_transform(), which can be useful for interpreting model outputs in the original scale. Standardization is sensitive to outliers. If your data has significant outliers, consider using scaling methods that are robust to outliers, such as RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because I wasn't sure how to work with de np.array, I converted everything back to pd.DataFrame\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=['x','y','z'])\n",
    "X_test = pd.DataFrame(X_test, columns=['x','y','z'])\n",
    "Y_train = pd.DataFrame(Y_train, columns=['x_future','y_future','z_future'])\n",
    "Y_test = pd.DataFrame(Y_test, columns=['x_future','y_future','z_future'])\n",
    "\n",
    "# This is not very robust. Better to work with the np.array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from Polynomial Regression (degree 2): 0.000758170500250553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "degree = 2\n",
    "\n",
    "# Create a pipeline for polynomial regression\n",
    "pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=degree)),  # Generate polynomial features\n",
    "    ('scaler', StandardScaler()),  # Optional scaling for features\n",
    "    ('model', LinearRegression())  # Linear regression model on polynomial features\n",
    "    ])\n",
    "\n",
    "# Fit the model on the training set\n",
    "pipeline.fit(X_train, Y_train['x_future'])\n",
    "\n",
    "# Predict on the test set\n",
    "y_hat_for_x = pipeline.predict(X_test)\n",
    "\n",
    "rmse_for_x = np.sqrt(mean_squared_error(Y_test['x_future'], y_hat_for_x))\n",
    "\n",
    "print(f'RMSE from Polynomial Regression (degree {degree}): {rmse_for_x}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from Polynomial Regression (degree 2): 0.023606595025463337\n"
     ]
    }
   ],
   "source": [
    "# Now for y\n",
    "\n",
    "# Fit the model on the training set\n",
    "pipeline.fit(X_train, Y_train['y_future'])\n",
    "\n",
    "# Predict on the test set\n",
    "y_hat_for_y = pipeline.predict(X_test)\n",
    "\n",
    "rmse_for_y = np.sqrt(mean_squared_error(Y_test['y_future'], y_hat_for_y))\n",
    "\n",
    "print(f'RMSE from Polynomial Regression (degree {degree}): {rmse_for_y}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from Polynomial Regression (degree 2): 0.012754605166158112\n"
     ]
    }
   ],
   "source": [
    "# Last, for z\n",
    "\n",
    "# Fit the model on the training set\n",
    "pipeline.fit(X_train, Y_train['z_future'])\n",
    "\n",
    "# Predict on the test set\n",
    "y_hat_for_z = pipeline.predict(X_test)\n",
    "\n",
    "rmse_for_z = np.sqrt(mean_squared_error(Y_test['z_future'], y_hat_for_z))\n",
    "\n",
    "print(f'RMSE from Polynomial Regression (degree {degree}): {rmse_for_z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600,), (600,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have to take into account only the last 600 values for x and z\n",
    "x_sliced = x[-600:]\n",
    "z_sliced = z[-600:]\n",
    "\n",
    "x_sliced.shape, z_sliced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(np.min(x_sliced), np.max(x_sliced))\n",
    "ax.set_ylim(np.min(z_sliced), np.max(z_sliced))\n",
    "\n",
    "# Create line objects for the two lines\n",
    "line1, = ax.plot([], [], lw=2, color='blue')\n",
    "line2, = ax.plot([], [], lw=2, color='red')\n",
    "\n",
    "# Initialize the animation\n",
    "def init():\n",
    "    line1.set_data([], [])\n",
    "    line2.set_data([], [])\n",
    "    return line1, line2\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame):\n",
    "    # Update the data for both lines\n",
    "    line1.set_data(x_sliced[:frame], z_sliced[:frame])\n",
    "    line2.set_data(y_hat_for_x[:frame], y_hat_for_z[:frame])\n",
    "    return line1, line2\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(t), init_func=init, blit=True, interval=20)\n",
    "HTML(ani.to_jshtml())  # This will display the animation in the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
